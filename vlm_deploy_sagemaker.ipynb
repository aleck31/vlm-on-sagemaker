{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLM éƒ¨ç½² - SageMaker Endpoint\n",
    "\n",
    "æœ¬notebookæä¾›å®Œæ•´çš„è§†è§‰è¯­è¨€æ¨¡å‹(VLM)åœ¨SageMakerä¸Šçš„ç”Ÿäº§çº§éƒ¨ç½²æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- æ¨¡å‹å‡†å¤‡å’ŒS3å­˜å‚¨\n",
    "- LMIå®¹å™¨é…ç½®\n",
    "- ç«¯ç‚¹éƒ¨ç½²\n",
    "- è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®\n",
    "- æ¨ç†è°ƒç”¨ç¤ºä¾‹\n",
    "\n",
    "## å‰ç½®è¦æ±‚\n",
    "- åœ¨SageMaker Studioæˆ–Notebook Instanceä¸­è¿è¡Œ\n",
    "- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ml.g6eå®ä¾‹é…é¢\n",
    "- å‡†å¤‡å¥½è¦éƒ¨ç½²çš„VLMæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†ä¾èµ–\n",
    "!pip list | grep -E \"(boto3|sagemaker|huggingface_hub|transformers)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‰éœ€å®‰è£…ç¼ºå¤±çš„çš„ä¾èµ–ï¼Œä¾‹å¦‚ï¼š\n",
    "!pip install boto3 sagemaker -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "import base64\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "from datetime import datetime\n",
    "\n",
    "# è·å–SageMaker sessionå’Œæƒé™\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess._region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "print(f\"Region: {region}, Role: {role}\")\n",
    "print(f\"Default bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. é…ç½®å‚æ•°\n",
    "\n",
    "æ ¹æ®ä½ çš„éœ€æ±‚ä¿®æ”¹ä»¥ä¸‹é…ç½®ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éƒ¨ç½²é…ç½®\n",
    "MODEL_S3_PATH = \"s3://your-bucket/models/qwen2-5-vl-7b/\"  # ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹S3è·¯å¾„\n",
    "INSTANCE_TYPE = \"ml.g6e.2xlarge\"  # å®ä¾‹ç±»å‹\n",
    "INITIAL_INSTANCE_COUNT = 2  # åˆå§‹å®ä¾‹æ•°é‡\n",
    "MODEL_NAME = \"qwen2-5-vl-7b\"  # æ¨¡å‹åç§°\n",
    "\n",
    "# æ‰©ç¼©å®¹é…ç½®\n",
    "MIN_CAPACITY = 2   # æœ€å°å®ä¾‹æ•°\n",
    "MAX_CAPACITY = 10  # æœ€å¤§å®ä¾‹æ•°\n",
    "TARGET_INVOCATIONS_PER_INSTANCE = 60  # æ¯å®ä¾‹æ¯åˆ†é’Ÿè°ƒç”¨æ•°ç›®æ ‡å€¼\n",
    "TARGET_GPU_UTILIZATION = 70.0  # ç›®æ ‡GPUåˆ©ç”¨ç‡\n",
    "TARGET_GPU_MEM_UTILIZATION = 85.0  # ç›®æ ‡GPUæ˜¾å­˜åˆ©ç”¨ç‡\n",
    "\n",
    "# LMIå®¹å™¨é…ç½®\n",
    "MAX_MODEL_LEN = 4096  # æœ€å¤§åºåˆ—é•¿åº¦\n",
    "MAX_BATCH_SIZE = 32   # æœ€å¤§æ‰¹å¤„ç†å¤§å°\n",
    "\n",
    "print(\"é…ç½®å‚æ•°:\")\n",
    "print(f\"æ¨¡å‹S3è·¯å¾„: {MODEL_S3_PATH}\")\n",
    "print(f\"å®ä¾‹ç±»å‹: {INSTANCE_TYPE}\")\n",
    "print(f\"åˆå§‹å®ä¾‹æ•°: {INITIAL_INSTANCE_COUNT}\")\n",
    "print(f\"æ‰©ç¼©å®¹èŒƒå›´: {MIN_CAPACITY}-{MAX_CAPACITY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. åˆ›å»ºLMIé…ç½®\n",
    "\n",
    "åˆ›å»ºserving.propertiesé…ç½®æ–‡ä»¶å¹¶æ‰“åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†å¹¶åˆ›å»ºé…ç½®ç›®å½•\n",
    "!rm -rf lmi_config\n",
    "os.makedirs(\"lmi_config\", exist_ok=True)\n",
    "\n",
    "# åˆ›å»ºserving.propertiesé…ç½®\n",
    "serving_config = f\"\"\"engine=Python\n",
    "option.model_id={MODEL_S3_PATH}\n",
    "option.dtype=fp16\n",
    "option.rolling_batch=vllm\n",
    "option.tensor_parallel_degree=1\n",
    "option.device_map=auto\n",
    "option.max_model_len={MAX_MODEL_LEN}\n",
    "option.max_rolling_batch_size={MAX_BATCH_SIZE}\n",
    "option.use_v2_block_manager=true\n",
    "option.enable_streaming=false\n",
    "\"\"\"\n",
    "\n",
    "# ä¿å­˜é…ç½®æ–‡ä»¶\n",
    "with open(\"lmi_config/serving.properties\", \"w\") as f:\n",
    "    f.write(serving_config)\n",
    "\n",
    "print(\"serving.propertieså†…å®¹:\")\n",
    "print(serving_config)\n",
    "\n",
    "# æ‰“åŒ…é…ç½®\n",
    "with tarfile.open(\"lmi_config.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"lmi_config\", arcname=\"lmi_config\")\n",
    "\n",
    "print(\"\\né…ç½®æ–‡ä»¶å·²æ‰“åŒ…ä¸º lmi_config.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. éƒ¨ç½²åˆ°SageMaker\n",
    "\n",
    "åˆ›å»ºæ¨¡å‹å¹¶éƒ¨ç½²åˆ°ç«¯ç‚¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨æœ€æ–°çš„LMIå®¹å™¨\n",
    "image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.33.0-lmi15.0.0-cu128\"\n",
    "print(f\"ä½¿ç”¨LMIå®¹å™¨: {image_uri}\")\n",
    "\n",
    "# ä¸Šä¼ é…ç½®åŒ…åˆ°S3\n",
    "s3_code_prefix = \"large-model-lmi/code\"\n",
    "code_artifact = sess.upload_data(\"lmi_config.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"é…ç½®åŒ…ä¸Šä¼ åˆ°: {code_artifact}\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)\n",
    "print(\"SageMakeræ¨¡å‹å·²åˆ›å»º\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆç«¯ç‚¹åç§°\n",
    "endpoint_name = f\"vlm-{MODEL_NAME}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "print(f\"ç«¯ç‚¹åç§°: {endpoint_name}\")\n",
    "\n",
    "# éƒ¨ç½²ç«¯ç‚¹ (å¼‚æ­¥)\n",
    "print(\"å¼€å§‹éƒ¨ç½²ç«¯ç‚¹...\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=INITIAL_INSTANCE_COUNT,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=False  # å¼‚æ­¥éƒ¨ç½²ï¼Œä¸ç­‰å¾…å®Œæˆ\n",
    ")\n",
    "\n",
    "print(f\"âœ… ç«¯ç‚¹éƒ¨ç½²å·²å¯åŠ¨: {endpoint_name}\")\n",
    "print(\"â±ï¸ é¢„è®¡éƒ¨ç½²æ—¶é—´: 10-15åˆ†é’Ÿ\")\n",
    "\n",
    "# ä¿å­˜ç«¯ç‚¹åç§°ä¾›åç»­ä½¿ç”¨\n",
    "with open(\"endpoint_name.save\", \"w\") as f:\n",
    "    f.write(endpoint_name)\n",
    "    \n",
    "print(f\"\\nğŸ“ ç«¯ç‚¹åç§°å·²ä¿å­˜åˆ° endpoint_name.save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç­‰å¾…ç«¯ç‚¹å°±ç»ª\n",
    "\n",
    "**é‡è¦**: å¿…é¡»ç­‰å¾…ç«¯ç‚¹çŠ¶æ€å˜ä¸º `InService` åæ‰èƒ½é…ç½®æ‰©ç¼©å®¹ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# åˆ›å»ºSageMakerå®¢æˆ·ç«¯\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "def check_endpoint_status(endpoint_name):\n",
    "    try:\n",
    "        response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        return response['EndpointStatus']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# ç­‰å¾…ç«¯ç‚¹å°±ç»ª\n",
    "print(f\"ç­‰å¾…ç«¯ç‚¹å°±ç»ª: {endpoint_name}\")\n",
    "print(\"è¿™å¯èƒ½éœ€è¦10-15åˆ†é’Ÿ...\")\n",
    "\n",
    "start_time = time.time()\n",
    "while True:\n",
    "    status = check_endpoint_status(endpoint_name)\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    \n",
    "    print(f\"\\râ±ï¸  {elapsed//60:02d}:{elapsed%60:02d} - çŠ¶æ€: {status}\", end=\"\", flush=True)\n",
    "    \n",
    "    if status == \"InService\":\n",
    "        print(f\"\\n\\nâœ… ç«¯ç‚¹å·²å°±ç»ª! æ€»è€—æ—¶: {elapsed//60}åˆ†{elapsed%60}ç§’\")\n",
    "        print(\"ç°åœ¨å¯ä»¥é…ç½®æ‰©ç¼©å®¹äº†\")\n",
    "        break\n",
    "    elif status in [\"Failed\", \"OutOfService\"]:\n",
    "        print(f\"\\n\\nâŒ ç«¯ç‚¹éƒ¨ç½²å¤±è´¥: {status}\")\n",
    "        # è·å–å¤±è´¥åŸå› \n",
    "        try:\n",
    "            response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "            if 'FailureReason' in response:\n",
    "                print(f\"å¤±è´¥åŸå› : {response['FailureReason']}\")\n",
    "        except:\n",
    "            pass\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡\n",
    "    \n",
    "    # è¶…æ—¶æ£€æŸ¥ (30åˆ†é’Ÿ)\n",
    "    if elapsed > 1800:\n",
    "        print(f\"\\n\\nâš ï¸  éƒ¨ç½²è¶…æ—¶ï¼Œè¯·æ£€æŸ¥SageMakeræ§åˆ¶å°\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. é…ç½®å¼¹æ€§æ‰©ç¼©å®¹\n",
    "\n",
    "**ä»…åœ¨ç«¯ç‚¹çŠ¶æ€ä¸º InService æ—¶æ‰§è¡Œæ­¤æ­¥éª¤ï¼**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºAuto Scalingå®¢æˆ·ç«¯\n",
    "autoscaling_client = boto3.client('application-autoscaling', region_name=region)\n",
    "\n",
    "# æ³¨å†Œæ‰©ç¼©å®¹ç›®æ ‡\n",
    "print(\"æ³¨å†Œæ‰©ç¼©å®¹ç›®æ ‡...\")\n",
    "try:\n",
    "    autoscaling_client.register_scalable_target(\n",
    "        ServiceNamespace='sagemaker',\n",
    "        ResourceId=f'endpoint/{endpoint_name}/variant/AllTraffic',\n",
    "        ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "        MinCapacity=MIN_CAPACITY,\n",
    "        MaxCapacity=MAX_CAPACITY\n",
    "    )\n",
    "    print(f\"âœ… æ‰©ç¼©å®¹ç›®æ ‡å·²æ³¨å†Œ: {MIN_CAPACITY}-{MAX_CAPACITY}ä¸ªå®ä¾‹\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ³¨å†Œæ‰©ç¼©å®¹ç›®æ ‡å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ‰©ç¼©å®¹ç­–ç•¥\n",
    "print(\"åˆ›å»ºæ‰©ç¼©å®¹ç­–ç•¥...\")\n",
    "try:\n",
    "    # æ–¹æ¡ˆ1: åŸºäºè°ƒç”¨é¢‘ç‡æ‰©ç¼©å®¹ (å½“å‰ä½¿ç”¨)\n",
    "    autoscaling_client.put_scaling_policy(\n",
    "        PolicyName=f'vlm-scaling-policy-{MODEL_NAME}',\n",
    "        ServiceNamespace='sagemaker',\n",
    "        ResourceId=f'endpoint/{endpoint_name}/variant/AllTraffic',\n",
    "        ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "        PolicyType='TargetTrackingScaling',\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            'TargetValue': TARGET_INVOCATIONS_PER_INSTANCE,\n",
    "            'PredefinedMetricSpecification': {\n",
    "                'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'\n",
    "            },\n",
    "            'ScaleOutCooldown': 180,  # 3åˆ†é’Ÿå¿«é€Ÿæ‰©å®¹\n",
    "            'ScaleInCooldown': 300    # 5åˆ†é’Ÿè°¨æ…ç¼©å®¹\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # æ–¹æ¡ˆ2: åŸºäºGPUåˆ©ç”¨ç‡æ‰©ç¼©å®¹ (ç¤ºä¾‹ä»£ç ï¼Œæœªå¯ç”¨)\n",
    "    # autoscaling_client.put_scaling_policy(\n",
    "    #     PolicyName=f'vlm-gpu-scaling-{MODEL_NAME}',\n",
    "    #     ServiceNamespace='sagemaker',\n",
    "    #     ResourceId=f'endpoint/{endpoint_name}/variant/AllTraffic',\n",
    "    #     ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    #     PolicyType='TargetTrackingScaling',\n",
    "    #     TargetTrackingScalingPolicyConfiguration={\n",
    "    #         'TargetValue': TARGET_GPU_UTILIZATION,\n",
    "    #         'CustomizedMetricSpecification': {\n",
    "    #             'MetricName': 'GPUUtilization',\n",
    "    #             'Namespace': 'AWS/SageMaker',\n",
    "    #             'Dimensions': [\n",
    "    #                 {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "    #                 {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "    #             ],\n",
    "    #             'Statistic': 'Average'\n",
    "    #         },\n",
    "    #         'ScaleOutCooldown': 180,  # 3åˆ†é’Ÿå¿«é€Ÿæ‰©å®¹\n",
    "    #         'ScaleInCooldown': 300   # 5åˆ†é’Ÿè°¨æ…ç¼©å®¹\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    # æ–¹æ¡ˆ3: åŸºäºGPUå†…å­˜åˆ©ç”¨ç‡æ‰©ç¼©å®¹ (ç¤ºä¾‹ä»£ç ï¼Œæœªå¯ç”¨)\n",
    "    # autoscaling_client.put_scaling_policy(\n",
    "    #     PolicyName=f'vlm-gpu-memory-scaling-{MODEL_NAME}',\n",
    "    #     ServiceNamespace='sagemaker',\n",
    "    #     ResourceId=f'endpoint/{endpoint_name}/variant/AllTraffic',\n",
    "    #     ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    #     PolicyType='TargetTrackingScaling',\n",
    "    #     TargetTrackingScalingPolicyConfiguration={\n",
    "    #         'TargetValue': TARGET_GPU_MEM_UTILIZATION,\n",
    "    #         'CustomizedMetricSpecification': {\n",
    "    #             'MetricName': 'GPUMemoryUtilization',\n",
    "    #             'Namespace': 'AWS/SageMaker',\n",
    "    #             'Dimensions': [\n",
    "    #                 {'Name': 'EndpointName', 'Value': endpoint_name},\n",
    "    #                 {'Name': 'VariantName', 'Value': 'AllTraffic'}\n",
    "    #             ],\n",
    "    #             'Statistic': 'Average'\n",
    "    #         },\n",
    "    #         'ScaleOutCooldown': 120,  # GPUå†…å­˜æ»¡æ—¶å¿«é€Ÿæ‰©å®¹\n",
    "    #         'ScaleInCooldown': 600   # ä¿å®ˆç¼©å®¹é¿å…é¢‘ç¹å˜åŒ–\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    print(f\"âœ… æ‰©ç¼©å®¹ç­–ç•¥å·²åˆ›å»º\")\n",
    "    print(f\"   ç›‘æ§æŒ‡æ ‡: æ¯å®ä¾‹è°ƒç”¨æ•°\")\n",
    "    print(f\"   ç›®æ ‡é˜ˆå€¼: {TARGET_INVOCATIONS_PER_INSTANCE}æ¬¡/å®ä¾‹/åˆ†é’Ÿ\")\n",
    "    print(f\"   æ‰©å®¹å†·å´: 3åˆ†é’Ÿ\")\n",
    "    print(f\"   ç¼©å®¹å†·å´: 5åˆ†é’Ÿ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åˆ›å»ºæ‰©ç¼©å®¹ç­–ç•¥å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ¨ç†è°ƒç”¨ç¤ºä¾‹\n",
    "\n",
    "ç«¯ç‚¹å°±ç»ªåï¼Œæµ‹è¯•æ¨ç†è°ƒç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºSageMaker Runtimeå®¢æˆ·ç«¯\n",
    "smr_client = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def call_vlm_endpoint(endpoint_name, text_prompt, image_path=None, max_tokens=512):\n",
    "    \"\"\"è°ƒç”¨VLMç«¯ç‚¹è¿›è¡Œæ¨ç†\"\"\"\n",
    "    \n",
    "    # æ„å»ºæ¶ˆæ¯å†…å®¹\n",
    "    content = [{\"type\": \"text\", \"text\": text_prompt}]\n",
    "    \n",
    "    # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ å›¾åƒå†…å®¹\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        encoded_image = encode_image(image_path)\n",
    "        image_url = f\"data:image/png;base64,{encoded_image}\"\n",
    "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": image_url}})\n",
    "    \n",
    "    # æ„å»ºè¯·æ±‚\n",
    "    prompt = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": max_tokens,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # è°ƒç”¨ç«¯ç‚¹\n",
    "        response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"application/json\",\n",
    "            Body=json.dumps(prompt),\n",
    "        )\n",
    "        \n",
    "        # è§£æå“åº”\n",
    "        result = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"è°ƒç”¨å¤±è´¥: {e}\"\n",
    "\n",
    "print(\"æ¨ç†è°ƒç”¨å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•æ–‡æœ¬æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•çº¯æ–‡æœ¬æ¨ç†\n",
    "print(\"æµ‹è¯•æ–‡æœ¬æ¨ç†...\")\n",
    "text_prompt = \"è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²\"\n",
    "print(f\"\\né—®é¢˜: {text_prompt}\")\n",
    "\n",
    "result = call_vlm_endpoint(endpoint_name, text_prompt)\n",
    "print(f\"\\nå›ç­”: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•è§†è§‰æ¨ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•è§†è§‰æ¨ç† (éœ€è¦æä¾›å›¾åƒæ–‡ä»¶)\n",
    "image_path = \"test_image.jpg\"  # ä¿®æ”¹ä¸ºä½ çš„æµ‹è¯•å›¾åƒè·¯å¾„\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"æµ‹è¯•è§†è§‰æ¨ç†: {image_path}\")\n",
    "    vision_prompt = \"è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹\"\n",
    "    print(f\"\\né—®é¢˜: {vision_prompt}\")\n",
    "    \n",
    "    result = call_vlm_endpoint(endpoint_name, vision_prompt, image_path)\n",
    "    print(f\"\\nå›ç­”: {result}\")\n",
    "else:\n",
    "    print(f\"æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {image_path}\")\n",
    "    print(\"è¯·ä¸Šä¼ æµ‹è¯•å›¾åƒæ–‡ä»¶ï¼Œæˆ–ä¿®æ”¹image_pathå˜é‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. éƒ¨ç½²æ€»ç»“\n",
    "\n",
    "æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯å’Œåç»­æ­¥éª¤ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ VLMç”Ÿäº§çº§éƒ¨ç½²å®Œæˆ!\")\n",
    "print(\"\\nğŸ“‹ éƒ¨ç½²ä¿¡æ¯:\")\n",
    "print(f\"   ç«¯ç‚¹åç§°: {endpoint_name}\")\n",
    "print(f\"   å®ä¾‹ç±»å‹: {INSTANCE_TYPE}\")\n",
    "print(f\"   åˆå§‹å®ä¾‹æ•°: {INITIAL_INSTANCE_COUNT}\")\n",
    "print(f\"   æ‰©ç¼©å®¹èŒƒå›´: {MIN_CAPACITY}-{MAX_CAPACITY}\")\n",
    "print(f\"   æ¨¡å‹è·¯å¾„: {MODEL_S3_PATH}\")\n",
    "\n",
    "print(\"\\nğŸ”§ å·²é…ç½®åŠŸèƒ½:\")\n",
    "print(\"   âœ… LMIå®¹å™¨éƒ¨ç½²\")\n",
    "print(\"   âœ… è‡ªåŠ¨æ‰©ç¼©å®¹\")\n",
    "print(\"   âœ… è´Ÿè½½å‡è¡¡\")\n",
    "print(\"   âœ… æ¨ç†è°ƒç”¨\")\n",
    "\n",
    "print(\"\\nğŸ“Š ç›‘æ§å»ºè®®:\")\n",
    "print(\"   - åœ¨CloudWatchä¸­ç›‘æ§GPUUtilizationæŒ‡æ ‡\")\n",
    "print(\"   - è®¾ç½®ModelLatencyå‘Šè­¦ (å»ºè®®<3ç§’)\")\n",
    "print(\"   - ç›‘æ§InvocationsPerInstanceæŒ‡æ ‡\")\n",
    "\n",
    "print(\"\\nğŸ’° æˆæœ¬ä¼˜åŒ–:\")\n",
    "print(\"   - è€ƒè™‘è´­ä¹°SageMaker Savings Plans (æœ€é«˜64%æŠ˜æ‰£)\")\n",
    "print(\"   - æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´æ‰©ç¼©å®¹å‚æ•°\")\n",
    "print(\"   - å¯ç”¨AWQé‡åŒ–å‡å°‘æ˜¾å­˜å ç”¨\")\n",
    "\n",
    "print(\"\\nğŸ”— ç›¸å…³èµ„æº:\")\n",
    "print(f\"   - SageMakeræ§åˆ¶å°: https://console.aws.amazon.com/sagemaker/home?region={region}#/endpoints/{endpoint_name}\")\n",
    "print(f\"   - CloudWatchæŒ‡æ ‡: https://console.aws.amazon.com/cloudwatch/home?region={region}#metricsV2:graph=~();search=SageMaker\")\n",
    "\n",
    "print(\"\\nâš ï¸  é‡è¦æé†’:\")\n",
    "print(\"   - ä¸ä½¿ç”¨æ—¶è¯·åˆ é™¤ç«¯ç‚¹ä»¥é¿å…äº§ç”Ÿè´¹ç”¨\")\n",
    "print(\"   - å®šæœŸæ£€æŸ¥å’Œä¼˜åŒ–æ‰©ç¼©å®¹ç­–ç•¥\")\n",
    "print(\"   - å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨VPCç«¯ç‚¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. æ¸…ç†èµ„æº (å¯é€‰)\n",
    "\n",
    "å¦‚æœéœ€è¦åˆ é™¤ç«¯ç‚¹ä»¥åœæ­¢è®¡è´¹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç æ¥åˆ é™¤ç«¯ç‚¹\n",
    "# è­¦å‘Š: è¿™å°†åˆ é™¤ç«¯ç‚¹å¹¶åœæ­¢æœåŠ¡\n",
    "\n",
    "# print(f\"åˆ é™¤ç«¯ç‚¹: {endpoint_name}\")\n",
    "# try:\n",
    "#     sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "#     print(\"âœ… ç«¯ç‚¹åˆ é™¤è¯·æ±‚å·²æäº¤\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âŒ åˆ é™¤ç«¯ç‚¹å¤±è´¥: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
