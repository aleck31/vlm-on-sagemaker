#!/usr/bin/env python3
"""
VLMæ¨¡å‹ä¸‹è½½è„šæœ¬ - ä»Hugging Faceä¸‹è½½æ¨¡å‹å¹¶ä¸Šä¼ åˆ°S3
"""

import os
import argparse
import shutil
from huggingface_hub import snapshot_download

# æ”¯æŒçš„æ¨¡å‹é…ç½®
SUPPORTED_MODELS = {
    "qwen2.5-vl-3b": "Qwen/Qwen2.5-VL-3B-Instruct",
    "qwen2.5-vl-7b": "Qwen/Qwen2.5-VL-7B-Instruct",
    "qwen2.5-vl-72b": "Qwen/Qwen2.5-VL-72B-Instruct"
}

def download_model(model_id, local_path):
    """ä»Hugging Faceä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
    print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_id}")
    print(f"ğŸ“ æœ¬åœ°ä¿å­˜: {local_path}")
    
    # è®¾ç½®é•œåƒæº
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    
    os.makedirs(local_path, exist_ok=True)
    
    # é‡è¯•æœºåˆ¶
    import time
    max_retries = 3
    for attempt in range(max_retries):
        try:
            snapshot_download(
                repo_id=model_id,
                local_dir=local_path,
                max_workers=5,  # å¤šçº¿ç¨‹ä¸‹è½½ (1çº¿ç¨‹=1æ–‡ä»¶)
            )
            print(f"âœ… ä¸‹è½½å®Œæˆ: {local_path}")
            return
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"âš ï¸ ä¸‹è½½å¤±è´¥ï¼Œ5ç§’åé‡è¯• ({attempt+1}/{max_retries}): {str(e)[:100]}")
                time.sleep(5)
            else:
                raise e

def upload_to_s3(local_path, s3_bucket, s3_prefix, region):
    """ä¸Šä¼ æ¨¡å‹åˆ°S3 - åªä¸Šä¼ SageMakeréƒ¨ç½²å¿…éœ€æ–‡ä»¶"""
    s3_path = f"s3://{s3_bucket}/{s3_prefix.rstrip('/')}"
    print(f"ğŸ“¤ ä¸Šä¼ åˆ°S3: {s3_path}")
    
    # SageMakeréƒ¨ç½²å¿…éœ€æ–‡ä»¶
    essential_files = [
        "config.json",
        "tokenizer.json", 
        "tokenizer_config.json",
        "generation_config.json",
        "preprocessor_config.json"  # VLMæ¨¡å‹å¿…éœ€
    ]
    
    # æŸ¥æ‰¾safetensorsæ–‡ä»¶
    import glob
    safetensors_files = glob.glob(os.path.join(local_path, "*.safetensors"))
    index_files = glob.glob(os.path.join(local_path, "*.index.json"))
    
    # ç»Ÿè®¡è¦ä¸Šä¼ çš„æ–‡ä»¶
    upload_files = []
    for file in essential_files:
        file_path = os.path.join(local_path, file)
        if os.path.exists(file_path):
            upload_files.append(file)
    
    # æ·»åŠ safetensorså’Œindexæ–‡ä»¶
    for file_path in safetensors_files + index_files:
        upload_files.append(os.path.basename(file_path))
    
    print(f"ğŸ“‹ ä¸Šä¼ æ–‡ä»¶: {len(upload_files)} ä¸ª")

    # é€ä¸ªä¸Šä¼ æ–‡ä»¶
    import subprocess
    success_count = 0
    for i, file in enumerate(upload_files, 1):
        local_file = os.path.join(local_path, file)
        s3_file = f"{s3_path}/{file}"
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(local_file)
        size_mb = file_size / (1024 * 1024)
        
        print(f"  - [{i}/{len(upload_files)}] ä¸Šä¼  {file} ({size_mb:.1f}MB)...")
        
        result = subprocess.run([
            "aws", "s3", "cp", local_file, s3_file,
            "--region", region
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            success_count += 1
            print(f"  âœ… å®Œæˆ")
        else:
            print(f"  âŒ å¤±è´¥: {result.stderr}")
    
    if success_count == len(upload_files):
        print(f"âœ… ä¸Šä¼ å®Œæˆ: {s3_path} ({success_count}ä¸ªæ–‡ä»¶)")
        return s3_path
    else:
        raise Exception(f"éƒ¨åˆ†æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {success_count}/{len(upload_files)}")

def main():
    parser = argparse.ArgumentParser(description="ä¸‹è½½VLMæ¨¡å‹å¹¶ä¸Šä¼ åˆ°S3")
    parser.add_argument("--model", required=True, choices=list(SUPPORTED_MODELS.keys()), help="æ¨¡å‹åç§°")
    parser.add_argument("--s3-bucket", required=True, help="S3å­˜å‚¨æ¡¶åç§°")
    parser.add_argument("--region", default="us-west-2", help="AWSåŒºåŸŸ")
    parser.add_argument("--keep-local", action="store_true", help="ä¿ç•™æœ¬åœ°æ–‡ä»¶")
    
    args = parser.parse_args()
    
    model_id = SUPPORTED_MODELS[args.model]
    local_path = f"./models/{args.model}"
    s3_prefix = f"models/{args.model}/"
    
    print("ğŸš€ VLMæ¨¡å‹ä¸‹è½½å™¨")
    print(f"ğŸ“‹ æ¨¡å‹: {args.model} ({model_id})")
    print(f"ğŸ“ æœ¬åœ°ç›®å½•: {local_path}")
    print(f"â˜ï¸  S3ç›®æ ‡: s3://{args.s3_bucket}/{s3_prefix}")
    print("-" * 60)
    
    try:
        # 1. ä¸‹è½½æ¨¡å‹
        download_model(model_id, local_path)
        
        # 2. ä¸Šä¼ åˆ°S3
        s3_path = upload_to_s3(local_path, args.s3_bucket, s3_prefix, args.region)
        
        # 3. æ¸…ç†æœ¬åœ°æ–‡ä»¶
        if not args.keep_local:
            print("ğŸ§¹ æ¸…ç†æœ¬åœ°æ–‡ä»¶...")
            shutil.rmtree(local_path)
            print("âœ… æœ¬åœ°æ–‡ä»¶å·²æ¸…ç†")
        else:
            print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ä¿ç•™åœ¨: {local_path}")
        
        # 4. è¾“å‡ºç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¨¡å‹ä¸‹è½½å’Œä¸Šä¼ å®Œæˆ!")
        print("\nğŸ“ åœ¨notebookä¸­ä½¿ç”¨:")
        print(f'MODEL_S3_PATH = "{s3_path}"')
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
